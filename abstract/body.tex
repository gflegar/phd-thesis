With the breakdown of Dennard scaling during the mid-2000s, and the end of
Moore's law on the horizon, hardware vendors, datacenters, and the high
performance computing community is turning its attention towards unconventional
hardware in hopes of continuing the exponential performance growth of
computational resources. Among the available hardware options, the next
generation of graphics processing units (GPUs), designed to support a wide
variety of workloads in addition to graphics processing, is achieving the widest
adoption. These processors are employed by the majority of today's most powerful
supercomputers to enable solving the world's most difficult problems in physics
simulations, weather forecasting, data analytics, social network analysis and
machine learning. The potential of GPUs for these problems can only be unlocked
by developing appropriate software, specifically tuned for the GPU architecture.
Fortunately, as these applications are decomposed into smaller building blocks,
it becomes obvious that the same ones appear in multiple applications. One of
them is the solution of large, sparse linear systems, which is the topic of this
thesis.

After a quick overview of the current state-of-the-art methods for the solution
of linear systems, detailed attention is dedicated to the class of Krylov
iterative methods. As opposed to deriving new methods, this work suggests
improvements of components that are found in all existing methods and represent
a high percentage of the total runtime. The components described are designed
for a single GPU, while scaling to multiple GPUs can be achieved either by
generalizing the same ideas, or by decomposing a larger problem into multiple
independent parts which can use the implementations described in this work.

The most time-consuming part of a Krylov method is often the matrix-vector
product. Two improvements are suggested: one for the widely used compressed
sparse row (CSR) matrix format, and another one for the coordinate (COO) format,
which has not yet achieved wide adoption. The new GPU implementation for the CSR
format is specifically tuned for matrices with irregular sparsity patterns and,
while experiencing slowdowns of up to 3x compared to the vendor library
implementation for regular patterns, it achieves up to 100x speedup for
irregular ones.  However, the slowdown can be eliminated by using a simple
heuristic that selects the superior implementation based on the sparsity pattern
of the matrix.  The new COO algorithm is suggested as the default matrix-vector
product implementation in cases when the details of the matrix' sparsity pattern
are not known in advance. This algorithm achieves 80\% higher minimal and 22\%
higher average performance than the newly developed CSR algorithm on a variety
of large matrices arising from real-world applications, making it an ideal
default choice for general-purpose libraries.

The second component being addressed is preconditioning. This work explores the
relatively simple class of block-Jacobi preconditioners and shows that they can
significantly increase the robustness and decrease the total runtime of Krylov
solvers for a certain class of matrices. Several algorithmic realizations of the
precondtioner are explored, and the one based on the Gauss-Jordan elimination
algorithm is found to offer the best performance in most situations, while the
variant based on LU factorization can be attractive for problems that converge
in few iterations.  Block-Jacobi precondtioning is analysed further via an
initial analysis of the effects that single and half precision floating point
storage have on this kind of preconditioners. The resulting adaptive precision
block-Jacobi preconditioner dynamically assigns storage precisions to individual
block at runtime, taking into account the numerical properties of the blocks. A
sequential implementation in a high-level language, backed by a theoretical
error analysis, shows that this preconditioner reduces the total memory transfer
volume, while keeping the quality of the preconditioner comparable to that of
the full precision variant. A theoretical energy model predicts that the
adaptive variant can offer energy savings of around 25\% compared to the full
precision block-Jacobi.

No new algorithm nor implementation is useful if it is not made available to the
high performance computing community. Thus, the final part of this thesis
explains a possible design of a sparse linear algebra library, which effectively
solves the problem of excessive composability of components for iterative
solution of linear systems. These ideas are used as the backbone of the open
source Ginkgo library, which also includes the most successful implementations
of matrix product algorithms and preconditioners described in this work.
