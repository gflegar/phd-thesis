\section{Designing Scientific Software for Sparse Computations}

With the previous chapters of this work focusing on the components for the
solution of linear systems, the natural next consideration is the integration of
these components into a complete software for the solution of linear systems.
The first obstacle is the endless amount of combinations in which distinct
components can be combined. Each matrix format can be used with any Krylov
method. On top of that, each combination can be enhanced with any
preconditioner, which could be available directly as a matrix provided by the
user (stored in one of the formats supported by the software, or even in a
custom format), generated from the system matrix as one of the standard
preconditioners (\eg, relaxation or factorization based), or even implemented as
a coarse (Krylov) solver. The system matrix may not even be stored explicitly,
but available as a specialized implementation provided by the user. The
preconditioners themselves may also be complex methods for the solution of
linear systems, as even the most common ILU-based preconditioners can be
constructed by selecting components from a pool of factorization methods that
generate a preconditioner, and a pool of linear system solution methods that are
used to solve systems with the upper and lower triangular factors generated by
the factorization. Another issue that increases the complexity of software
design is the heterogeneity of modern hardware. If the goal of the software is
to support computation on various devices, or even collaborative computation on
a heterogeneous platform, concepts defining the hardware resources that are used
to perform the computations also have to be added to the design.

While there are various high performance libraries that try to address these
issues~\cite{magma,vienna-cl,paralution}, they usually lack at least one of the
points mentioned above, or are somewhat difficult to use. This section proposes
one possible theoretical design aimed at solving these issues and briefly
describes a new library that is based on this design.

\subsection{Matrices}
TODO: Derivation of the matrix application linear operator $L_A$.

\subsection{Linear Systems}
TODO: Derivation of the linear system solver operator $S_A$.

\subsection{Preconditioners}
TODO: Derivation of the preconditioner linear operator $P^\Pi_A$.
\subsection{Linear Operators --- Towards a Generic Interface for Sparse
            Computations}
TODO: The linear operator and linear operator factory abstractions as the basis
      of the library for sparse computations.
      If I feel like it, maybe I add the new ideas I have about having subspaces
      as first-class citizens in the library, which I feel are a better
      abstraction than vectors we're usually talking about - both for linear
      solvers, and for getting towards eigensolvers. Just to write it down
      somewhere, and maybe someone adds them to Ginkgo.
\subsection{Numerical Methods}
TODO: The issue of numerics and convergence - rounding errors affecting
matrices, preconditioners and solvers, limited convergence affecting solvers and
some preconditioners. The difference between the interface (what we want to
compute) and the numerical method (what we are actually computing), i.e. the
response to ``a Krylov solver is not a linear operator'' comment.

\subsection{Ginkgo: A High Performance Linear Operator Library}
TODO: The Ginkgo library implementing the things discussed above. Open and
modern development practices.

